{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [],
   "source": [
    "import torch\n",
    "import torch.nn as nn\n",
    "import torch.optim as optim\n",
    "import torchvision\n",
    "import torchvision.transforms as transforms\n",
    "from torchvision.models import resnet18, resnet34, resnet50\n",
    "import numpy as np\n",
    "from torch.utils.data import DataLoader\n",
    "import time"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Implement FGSM Attack\n",
    "def fgsm_attack(model, images, labels, epsilon, device, criterion):\n",
    "    \"\"\"Fast Gradient Sign Method attack\"\"\"\n",
    "    perturbed_images = images.clone().detach()\n",
    "    perturbed_images.requires_grad = True\n",
    "    \n",
    "    outputs = model(perturbed_images)\n",
    "    loss = criterion(outputs, labels)\n",
    "    \n",
    "    # Compute gradients\n",
    "    loss.backward()\n",
    "    \n",
    "    # Create perturbation using gradient sign\n",
    "    sign_data_grad = perturbed_images.grad.sign()\n",
    "    \n",
    "    # Add perturbation to create adversarial example\n",
    "    perturbed_images = perturbed_images + epsilon * sign_data_grad\n",
    "    perturbed_images = torch.clamp(perturbed_images, 0, 1)\n",
    "    \n",
    "    return perturbed_images.detach()\n",
    "\n",
    "# Implement PGD Attack\n",
    "def pgd_attack(model, images, labels, epsilon, alpha, num_iter, device, criterion, random_start=True):\n",
    "    \"\"\"Projected Gradient Descent attack\"\"\"\n",
    "    perturbed_images = images.clone().detach()\n",
    "    \n",
    "    # Add random noise if specified\n",
    "    if random_start:\n",
    "        perturbed_images = perturbed_images + torch.empty_like(perturbed_images).uniform_(-epsilon, epsilon)\n",
    "        perturbed_images = torch.clamp(perturbed_images, 0, 1)\n",
    "\n",
    "    for i in range(num_iter):\n",
    "        perturbed_images.requires_grad = True\n",
    "        outputs = model(perturbed_images)\n",
    "        model.zero_grad()\n",
    "        loss = criterion(outputs, labels)\n",
    "        loss.backward()\n",
    "        \n",
    "        # Step in direction of gradient\n",
    "        adv_images = perturbed_images + alpha * perturbed_images.grad.sign()\n",
    "        \n",
    "        # Project back to epsilon ball\n",
    "        eta = torch.clamp(adv_images - images, -epsilon, epsilon)\n",
    "        perturbed_images = torch.clamp(images + eta, 0, 1).detach()\n",
    "\n",
    "    return perturbed_images\n",
    "\n",
    "# Set device\n",
    "device = torch.device(\"cuda:0\" if torch.cuda.is_available() else \"cpu\")\n",
    "print(f\"Using device: {device}\")\n",
    "\n",
    "# Data loading and preprocessing\n",
    "def load_data(data_path, batch_size=64):\n",
    "    \"\"\"Load and preprocess dataset\"\"\"\n",
    "    transform = transforms.Compose([\n",
    "        transforms.ToTensor(),\n",
    "        transforms.Normalize((0.4914, 0.4822, 0.4465), (0.2023, 0.1994, 0.2010))  # For CIFAR-10, adjust if needed\n",
    "    ])\n",
    "    \n",
    "    # Load your dataset here\n",
    "    # This is a placeholder - adjust according to your actual data format\n",
    "    train_dataset = torchvision.datasets.CIFAR10(root=data_path, train=True, download=True, transform=transform)\n",
    "    train_loader = DataLoader(train_dataset, batch_size=batch_size, shuffle=True, num_workers=2)\n",
    "    \n",
    "    test_dataset = torchvision.datasets.CIFAR10(root=data_path, train=False, download=True, transform=transform)\n",
    "    test_loader = DataLoader(test_dataset, batch_size=batch_size, shuffle=False, num_workers=2)\n",
    "    \n",
    "    return train_loader, test_loader\n",
    "\n",
    "# Model setup\n",
    "def get_model(model_name=\"resnet18\", num_classes=10):\n",
    "    \"\"\"Initialize one of the allowed ResNet models\"\"\"\n",
    "    if model_name == \"resnet18\":\n",
    "        model = resnet18(pretrained=True)\n",
    "    elif model_name == \"resnet34\":\n",
    "        model = resnet34(pretrained=True)\n",
    "    elif model_name == \"resnet50\":\n",
    "        model = resnet50(pretrained=True)\n",
    "    else:\n",
    "        raise ValueError(f\"Model {model_name} not supported. Use one of: resnet18, resnet34, resnet50\")\n",
    "    \n",
    "    # Modify final layer for the given number of classes\n",
    "    model.fc = nn.Linear(model.fc.in_features, num_classes)\n",
    "    return model.to(device)\n",
    "\n",
    "# Adversarial training function\n",
    "def train_robust_model(model, train_loader, val_loader, num_epochs=100, epsilon=8/255, alpha=2/255, num_iter=10):\n",
    "    \"\"\"Train model with adversarial training\"\"\"\n",
    "    model.train()\n",
    "    criterion = nn.CrossEntropyLoss()\n",
    "    optimizer = optim.SGD(model.parameters(), lr=0.01, momentum=0.9, weight_decay=5e-4)\n",
    "    scheduler = optim.lr_scheduler.CosineAnnealingLR(optimizer, T_max=num_epochs)\n",
    "    \n",
    "    for epoch in range(num_epochs):\n",
    "        running_loss = 0.0\n",
    "        correct = 0\n",
    "        total = 0\n",
    "        \n",
    "        for i, (images, labels) in enumerate(train_loader):\n",
    "            images, labels = images.to(device), labels.to(device)\n",
    "            \n",
    "            # Choose either clean, FGSM, or PGD samples for this batch\n",
    "            attack_type = np.random.choice(['clean', 'fgsm', 'pgd'], p=[0.3, 0.3, 0.4])\n",
    "            \n",
    "            if attack_type == 'fgsm':\n",
    "                perturbed_images = fgsm_attack(model, images, labels, epsilon, device, criterion)\n",
    "            elif attack_type == 'pgd':\n",
    "                perturbed_images = pgd_attack(model, images, labels, epsilon, alpha, num_iter, device, criterion)\n",
    "            else:  # clean\n",
    "                perturbed_images = images\n",
    "            \n",
    "            # Forward pass and optimization\n",
    "            optimizer.zero_grad()\n",
    "            outputs = model(perturbed_images)\n",
    "            loss = criterion(outputs, labels)\n",
    "            loss.backward()\n",
    "            optimizer.step()\n",
    "            \n",
    "            running_loss += loss.item()\n",
    "            _, predicted = outputs.max(1)\n",
    "            total += labels.size(0)\n",
    "            correct += predicted.eq(labels).sum().item()\n",
    "            \n",
    "            if (i + 1) % 100 == 0:\n",
    "                print(f\"Epoch {epoch+1}/{num_epochs}, Step {i+1}/{len(train_loader)}, Loss: {loss.item():.4f}\")\n",
    "        \n",
    "        scheduler.step()\n",
    "        \n",
    "        # Print epoch stats\n",
    "        train_accuracy = 100 * correct / total\n",
    "        print(f\"Epoch {epoch+1}/{num_epochs}, Loss: {running_loss/len(train_loader):.4f}, Accuracy: {train_accuracy:.2f}%\")\n",
    "        \n",
    "        # Evaluate every 5 epochs\n",
    "        if (epoch + 1) % 5 == 0:\n",
    "            evaluate_model(model, val_loader, epsilon, alpha, num_iter)\n",
    "    \n",
    "    return model\n",
    "\n",
    "# Evaluation function\n",
    "def evaluate_model(model, data_loader, epsilon=8/255, alpha=2/255, num_iter=10):\n",
    "    \"\"\"Evaluate model performance on clean and adversarial examples\"\"\"\n",
    "    model.eval()\n",
    "    criterion = nn.CrossEntropyLoss()\n",
    "    \n",
    "    # Evaluate on clean data\n",
    "    correct_clean = 0\n",
    "    total = 0\n",
    "    with torch.no_grad():\n",
    "        for images, labels in data_loader:\n",
    "            images, labels = images.to(device), labels.to(device)\n",
    "            outputs = model(images)\n",
    "            _, predicted = outputs.max(1)\n",
    "            total += labels.size(0)\n",
    "            correct_clean += predicted.eq(labels).sum().item()\n",
    "    clean_acc = 100 * correct_clean / total\n",
    "    \n",
    "    # Evaluate on FGSM examples\n",
    "    correct_fgsm = 0\n",
    "    for images, labels in data_loader:\n",
    "        images, labels = images.to(device), labels.to(device)\n",
    "        perturbed_images = fgsm_attack(model, images, labels, epsilon, device, criterion)\n",
    "        with torch.no_grad():\n",
    "            outputs = model(perturbed_images)\n",
    "            _, predicted = outputs.max(1)\n",
    "            correct_fgsm += predicted.eq(labels).sum().item()\n",
    "    fgsm_acc = 100 * correct_fgsm / total\n",
    "    \n",
    "    # Evaluate on PGD examples\n",
    "    correct_pgd = 0\n",
    "    for images, labels in data_loader:\n",
    "        images, labels = images.to(device), labels.to(device)\n",
    "        perturbed_images = pgd_attack(model, images, labels, epsilon, alpha, num_iter, device, criterion)\n",
    "        with torch.no_grad():\n",
    "            outputs = model(perturbed_images)\n",
    "            _, predicted = outputs.max(1)\n",
    "            correct_pgd += predicted.eq(labels).sum().item()\n",
    "    pgd_acc = 100 * correct_pgd / total\n",
    "    \n",
    "    print(f\"Clean accuracy: {clean_acc:.2f}%\")\n",
    "    print(f\"FGSM accuracy: {fgsm_acc:.2f}%\")\n",
    "    print(f\"PGD accuracy: {pgd_acc:.2f}%\")\n",
    "    \n",
    "    return clean_acc, fgsm_acc, pgd_acc\n",
    "\n",
    "# Function to save model for submission\n",
    "def save_model_for_submission(model, model_class, path=\"robust_model.pt\"):\n",
    "    \"\"\"Save model state dict and class name for submission\"\"\"\n",
    "    torch.save({\n",
    "        'model_state_dict': model.state_dict(),\n",
    "        'model_class': model_class\n",
    "    }, path)\n",
    "    print(f\"Model saved to {path}\")\n",
    "\n",
    "# Main execution (uncomment to run)\n",
    "\"\"\"\n",
    "# Set parameters\n",
    "data_path = './data'  # Adjust to your data path\n",
    "model_name = 'resnet18'  # Choose from resnet18, resnet34, resnet50\n",
    "num_classes = 10  # Adjust based on your dataset\n",
    "\n",
    "# Load data\n",
    "train_loader, test_loader = load_data(data_path)\n",
    "\n",
    "# Initialize model\n",
    "model = get_model(model_name, num_classes)\n",
    "\n",
    "# Train model\n",
    "model = train_robust_model(model, train_loader, test_loader)\n",
    "\n",
    "# Final evaluation\n",
    "clean_acc, fgsm_acc, pgd_acc = evaluate_model(model, test_loader)\n",
    "\n",
    "# Save model for submission\n",
    "save_model_for_submission(model, model_name)\n",
    "\"\"\""
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.12.4"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
